{"cells":[{"cell_type":"markdown","id":"82113fee","metadata":{"id":"82113fee"},"source":["# Multiple Linear Regression"]},{"cell_type":"markdown","source":["In this notebook we will expand our simple linear regression model that we built to predict car prices in the last chapter to include several independent variables in order to produce better predictions."],"metadata":{"id":"MPvBOTYOoAWh"},"id":"MPvBOTYOoAWh"},{"cell_type":"markdown","id":"e08c665f","metadata":{"id":"e08c665f"},"source":["### Package and Data Loading"]},{"cell_type":"markdown","source":["As before, we will import the required packages and our car price data set."],"metadata":{"id":"CeDlsRU1oEpu"},"id":"CeDlsRU1oEpu"},{"cell_type":"code","execution_count":null,"id":"06b403ac","metadata":{"id":"06b403ac"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plot\n","import statsmodels.api as stats\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"id":"f4865a4d","metadata":{"id":"f4865a4d"},"outputs":[],"source":["carprice_df = pd.read_csv('CarPrice_Assignment.csv')"]},{"cell_type":"markdown","id":"fdb2c710","metadata":{"id":"fdb2c710"},"source":["### Assessing the Data"]},{"cell_type":"code","execution_count":null,"id":"94e1557d","metadata":{"id":"94e1557d"},"outputs":[],"source":["carprice_df"]},{"cell_type":"code","execution_count":null,"id":"4fa9c004","metadata":{"id":"4fa9c004"},"outputs":[],"source":["carprice_df"]},{"cell_type":"code","execution_count":null,"id":"09e79eb4","metadata":{"id":"09e79eb4"},"outputs":[],"source":["carprice_df"]},{"cell_type":"markdown","source":["Here we are checking the number of unique values in specifically the categorical variables using df.select_dtypes()"],"metadata":{"id":"zSWfezUaqUNG"},"id":"zSWfezUaqUNG"},{"cell_type":"code","execution_count":null,"id":"72e73d4b","metadata":{"id":"72e73d4b"},"outputs":[],"source":["carprice_df"]},{"cell_type":"markdown","source":["As we can see, the data contains a mixture of numeric types and categorical (object) types. We will remove the car_ID field from the data as this is only an identifier. For the purposes of this lesson we will also remove CarName from the data as it contains a large number of unique values (How could we extract more useful information from this variable?)."],"metadata":{"id":"OAGwsfNKqJl4"},"id":"OAGwsfNKqJl4"},{"cell_type":"code","execution_count":null,"id":"da0d6f86","metadata":{"id":"da0d6f86"},"outputs":[],"source":["carprice_df = carprice_df.drop(columns=['car_ID', 'CarName'])"]},{"cell_type":"markdown","id":"d286e93c","metadata":{"id":"d286e93c"},"source":["## Basic Multiple Regression Model"]},{"cell_type":"code","execution_count":null,"id":"ecea0899","metadata":{"id":"ecea0899"},"outputs":[],"source":["Y_basic = \n","X_basic = "]},{"cell_type":"code","execution_count":null,"id":"b96ecac4","metadata":{"id":"b96ecac4"},"outputs":[],"source":["model_basic = \n","results_basic = "]},{"cell_type":"markdown","source":["We can see our results and the parameters for each of the independent variables using the .summary() attribute again."],"metadata":{"id":"h8cIQ9xwqohj"},"id":"h8cIQ9xwqohj"},{"cell_type":"code","execution_count":null,"id":"10506c50","metadata":{"id":"10506c50"},"outputs":[],"source":["print(results_basic.summary())"]},{"cell_type":"markdown","id":"31956d89","metadata":{"id":"31956d89"},"source":["## Full Multiple Regression Model"]},{"cell_type":"markdown","source":["We can look at the correlations between different numerical variables in a handy way using a correlation matrix - this allows us to see the correlation between all pairs of variables at once. We can then remove some of the independent variables that are highly correlated and would cause problems with the algorithm due to multicollinearity. We can create this correlation matrix using the df.corr() method. We add a red/blue heatmap to better see where the extreme correlations are."],"metadata":{"id":"7WQqmOuXqyzb"},"id":"7WQqmOuXqyzb"},{"cell_type":"code","execution_count":null,"id":"1e641dab","metadata":{"id":"1e641dab"},"outputs":[],"source":["carprice_df.select_dtypes(exclude='object')"]},{"cell_type":"code","execution_count":null,"id":"c5ea1d43","metadata":{"id":"c5ea1d43"},"outputs":[],"source":["carprice_df = carprice_df"]},{"cell_type":"markdown","id":"878eabcf","metadata":{"id":"878eabcf"},"source":["#### One Hot Encoding"]},{"cell_type":"code","execution_count":null,"id":"b11ef531","metadata":{"id":"b11ef531"},"outputs":[],"source":["dummy = "]},{"cell_type":"code","execution_count":null,"id":"5ac0cb80","metadata":{"id":"5ac0cb80"},"outputs":[],"source":["carprice_df = pd.concat([carprice_df.select_dtypes(exclude='object'), dummy], axis=1)"]},{"cell_type":"markdown","id":"19fd576c","metadata":{"id":"19fd576c"},"source":["We can repeat the above process where we remove highly correlated variables, now including the one hot encoded features."]},{"cell_type":"code","execution_count":null,"id":"149d5e75","metadata":{"id":"149d5e75"},"outputs":[],"source":["carprice_df.corr().style.background_gradient(cmap='coolwarm')"]},{"cell_type":"code","execution_count":null,"id":"8d2f1731","metadata":{"id":"8d2f1731"},"outputs":[],"source":["carprice_df = carprice_df.drop(columns=['compressionratio', 'drivewheel_fwd', 'enginetype_rotor', 'fuelsystem_4bbl', 'fuelsystem_idi'])"]},{"cell_type":"code","execution_count":null,"id":"0512fb13","metadata":{"id":"0512fb13"},"outputs":[],"source":["carprice_df.shape"]},{"cell_type":"markdown","id":"363aebd7","metadata":{"id":"363aebd7"},"source":["### Test/Train Split"]},{"cell_type":"code","execution_count":null,"id":"b3c0bac1","metadata":{"id":"b3c0bac1"},"outputs":[],"source":["train_df = carprice_df.sample(frac = 0.7, random_state = 99) #random state is a seed value\n","test_df = carprice_df.drop(train_df.index)"]},{"cell_type":"code","execution_count":null,"id":"9f5fbde2","metadata":{"id":"9f5fbde2"},"outputs":[],"source":["train_df.shape"]},{"cell_type":"code","execution_count":null,"id":"9739549d","metadata":{"id":"9739549d"},"outputs":[],"source":["test_df.shape"]},{"cell_type":"markdown","id":"e9c41924","metadata":{"id":"e9c41924"},"source":["### Fitting the Linear Regression Model"]},{"cell_type":"markdown","source":["We once again use statsmodels to fit our linear regression model. We do this in the same way as the previous notebook except now our X_train contains all of our independent variables (plus the constant column)."],"metadata":{"id":"NQDdmdtUrVK_"},"id":"NQDdmdtUrVK_"},{"cell_type":"code","execution_count":null,"id":"f7cc806d","metadata":{"id":"f7cc806d"},"outputs":[],"source":["Y_train = \n","X_train = "]},{"cell_type":"code","execution_count":null,"id":"bb30ebfb","metadata":{"id":"bb30ebfb"},"outputs":[],"source":["model_carprice = stats.OLS(Y_train, X_train)\n","results_carprice = model_carprice.fit()"]},{"cell_type":"code","execution_count":null,"id":"56f28f91","metadata":{"id":"56f28f91"},"outputs":[],"source":["print(results_carprice.summary())"]},{"cell_type":"code","execution_count":null,"id":"23d39bae","metadata":{"id":"23d39bae"},"outputs":[],"source":["print('The sum of square residuals is {:.1f}'.format(results_carprice.ssr))"]},{"cell_type":"markdown","source":["We can also use our test set to compare our predictions with the observed values."],"metadata":{"id":"msdEYDTqrflw"},"id":"msdEYDTqrflw"},{"cell_type":"code","execution_count":null,"id":"9a7de989","metadata":{"id":"9a7de989"},"outputs":[],"source":["Y_test = test_df.price\n","test_df = stats.add_constant(test_df)\n","X_test = test_df[X_train.columns]"]},{"cell_type":"code","execution_count":null,"id":"23f45378","metadata":{"id":"23f45378"},"outputs":[],"source":["test_predictions = results_carprice.predict(X_test)"]},{"cell_type":"code","execution_count":null,"id":"c5a650f9","metadata":{"id":"c5a650f9"},"outputs":[],"source":["plot.scatter(test_predictions, Y_test)\n","plot.plot([5000, 50000], [5000, 50000], c='k', ls='--')\n","plot.xlabel('Predicted Price [$]')\n","plot.ylabel('Observed Price [$]')\n","plot.show()"]},{"cell_type":"markdown","id":"f04b7e8a","metadata":{"id":"f04b7e8a"},"source":["## Scikit-Learn\n"]},{"cell_type":"code","execution_count":null,"id":"8262a580","metadata":{"id":"8262a580"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","id":"f24100ef","metadata":{"id":"f24100ef"},"source":["### Test/Train Split"]},{"cell_type":"code","execution_count":null,"id":"90a0b423","metadata":{"id":"90a0b423"},"outputs":[],"source":["Y = carprice_df.price\n","X = carprice_df.drop(columns=['price'])"]},{"cell_type":"code","execution_count":null,"id":"8549c968","metadata":{"id":"8549c968"},"outputs":[],"source":["sk_X_train, sk_X_test, sk_Y_train, sk_Y_test = train_test_split(X, Y, test_size=0.3, random_state=99)"]},{"cell_type":"code","execution_count":null,"id":"51345634","metadata":{"id":"51345634"},"outputs":[],"source":["regressor = LinearRegression()  \n","regressor.fit(sk_X_train, sk_Y_train)"]},{"cell_type":"code","execution_count":null,"id":"41e4fa65","metadata":{"id":"41e4fa65"},"outputs":[],"source":["sk_intercept_carprice = regressor.intercept_\n","sk_engsize_coeffs = regressor.coef_\n","sk_ssr_carprice = np.sum((sk_Y_train-regressor.predict(sk_X_train))**2)"]},{"cell_type":"code","execution_count":null,"id":"be98ac49","metadata":{"id":"be98ac49"},"outputs":[],"source":["pd.Series(sk_engsize_coeffs, index=sk_X_train.columns)"]},{"cell_type":"code","execution_count":null,"id":"ae34397d","metadata":{"id":"ae34397d"},"outputs":[],"source":["print('The intercept value is {:.1f}'.format(sk_intercept_carprice))\n","print('The sum of square residuals is {:.1f}'.format(sk_ssr_carprice))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Multiple Linear Regression - Blank.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}